The calculus for circuits is analogous to Boole’s propositional logic, and the analogy may be seen with the following Table 2.11: Table 2.11 Circuits and Boolean algebra Symbol Digital circuits Propositional logic X The circuit X The proposition X 0 The circuit is closed The proposition is false 1 The circuit is open The proposition is true X + Y Series connection of circuits X and Y The proposition which is true when either X or Y is true, and false otherwise X rY Parallel connection of circuits X and Y The proposition which is true when both X and Y are true. X′ The circuit that is open when X is closed and vice versa X′ is false when X is true and vice versa. X = Y The circuits open and close simultaneously Each proposition implies the other 60 2 Foundations Any expression formed with the additive, multiplicative and negation operators forms a circuit containing serial and parallel connections only. To ﬁnd the simplest circuit with the least number of contacts all that is required is to manipulate the mathematical expression into the form in which the fewest variables appear. For example, the circuit represent by f (X,Y,Z) = XY′ + X′ Z′ + XZ′ is given in Fig. 2.19: X Y´ X´ Z´ X Z´ Fig. 2.19 Simplifying circuits However, this circuit may be simpliﬁed by noting that (Fig. 2.20): f (X,Y,Z) = XY′ + X′Z′ + XZ′ = XY′ + (X′ + X)Z′ = XY′ + 1Z′ = XY′ + Z′ Fig. 2.20 Simpliﬁed circuit X Y´ Z´ 2.6.2 Information Theory Early pioneering work on Information Theory was done by Nyquist in the 1920s (Fig. 2.21). Shannon is recognised as the father of Information Theory due to his work in formulating a mathematical foundation for the ﬁeld in his classic 1948 paper “A Mathematical Theory of Communication” [Sha:48]. The key problem to be solved in information theory is the reliable transmission of a message from a source point over a channel to a destination point.19 The problem is that there may be noise in the channel that may distort the message being sent, and the engineer wishes to ensure that the message received has not been distorted by noise. The objective of information theory is to provide answers to how rapidly or reliably a 19 The system designer may also place a device called an encoder between the source and the channel and a device called a decoder between the output of the channel and the destination. 2.6 Shannon 61 Source Destination Transmitter Receiver Message Message Noise Signal Received Signal Fig. 2.21 Information theory message may be sent from the source point to the destination point. The meanings of the messages are ignored as they are irrelevant from an engineering viewpoint. Shannon’s theory of information is based on probability theory and statistics. One important concept is that of entropy which measures the level of uncertainty associated with a random variable X. The amount of information in common between two random variables can be used to ﬁnd the communication rate across a channel. Shannon derived a fundamental limit theorem, and this theorem states the limitations on the reliability level that may be achieved for a given source and channel. Further, he showed that for large encoder delays, it is possible to achieve performance that is essentially as good as the fundamental limit. Shannon’s noisy- channel coding theorem states that reliable communication is possible over noisy channels provided that the rate of communication is below a certain threshold called the “channel capacity”. The channel capacity can be approached by using appropri- ate encoding and decoding systems. Shannon’s work established the fundamental limits on communication. Shannon’s theory also showed how to design more efﬁcient communication and storage systems. 2.6.3 Cryptography Shannon is considered the father of modern cryptography with his inﬂuential 1949 paper “Communication Theory of Secrecy Systems” [Sha:49]. His work established a solid theoretical basis for cryptography and for cryptanalysis. Shan- non deﬁned the basic mathematical structures that underly secrecy systems, and a secrecy system is deﬁned to be a transformation from the space of all mes- sages to the space of all cryptograms. Each possible transformation corresponds to encryption with a particular key. The transformations are generally reversible as this allows the original message to be deciphered from the cryptogram provided that the key is known. The basic operation of a secrecy system is described in Fig. 2.22: 62 2 Foundations Message Source Encipherer Tk Decipherer Tk –1 Message Cryptogram E M Key Source Key K Enemy Cryptanalyst Message M Fig. 2.22 Cryptography First, the key is selected and sent to the receiving point. The choice of key deter-
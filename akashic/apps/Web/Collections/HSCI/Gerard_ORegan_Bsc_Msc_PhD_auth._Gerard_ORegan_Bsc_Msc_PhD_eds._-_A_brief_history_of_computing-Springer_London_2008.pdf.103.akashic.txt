the axiomatization was consistent. The speciﬁc objectives of Hilbert’s programme were to: r Develop a formal system where the truth or falisty of any mathematical statement may be determined. r A proof that the system is consistent (i.e., that no contradictions may be derived). A proof in a formal system consists of a sequence of formulate, where each formula is either an axiom or derived from one or more preceding formulae in the sequence by one of the rules of inference. Hilbert believed that every mathematical problem could be solved and therefore expected that the formal system of mathematics would be completes (that is, all truths could be proved within the system) and decidable: i.e., that the truth or falisty of any mathematical proposition could be determined by an algorithm. Russell and Whitehead published Principia Mathematica in 1910, and this three- volume work on the foundations of mathematics attempted to derive all mathemat- ical truths in arithmetic from a well-deﬁned set of axioms and rules of inference. The questions remained whether the Principia was complete and consistent. That is, is it possible to derive all the truths of arithmetic in the system and is it possible to derive a contradiction from the Principia’s axioms? G¨odel’s second incompleteness theorem [Goe:31] showed that ﬁrst order arith- metic is incomplete, and that the consistency of ﬁrst-order arithmetic cannot be proved within the system. Therefore, if ﬁrst-order arithmetic cannot prove its own consistency, then it cannot prove the consistency of any system that contains ﬁrst- order arithmetic. Hilbert also believed that formalism would be decidable: there would be a mechanical procedure (or algorithm) to determine whether a particular statement was true or false. However, Church and Turing independently showed this to be impossible in 1936. The only way to determine whether a statement is true or false is to try to solve it. 5.10 Robots 171 5.10 Robots The ﬁrst use of the term “robot” was by the Czech playwright Karel Capek in his play “Rossum’s Universal Robots” performed in Prague in 1921. The word “robot” is from the Czech word for forced labour. The play was discussed earlier in Section 5.5, and the theme explored is whether it is ethical to exploit artiﬁcial workers in a factory, and what response the robots should make to their exploitation. Capek’s robots were not mechanical or metal in nature and were instead created through chemical means. Capek, in fact, rejected the idea that machines created from metal could think of feel. The science ﬁction writer Asimov wrote several stories about robots in the 1940s including the story of a robotherapist.22 He predicted the rise of a major robot industry, and he also introduced a set of rules (or laws) which stipulated the good behaviors that robots are expected to observe. These are known as the three Laws of Robotics and a fourth law was later added by Asimov (Table 5.2). The term “robot” is deﬁned by the Robot Institute of America as: Deﬁnition 5.1 (Robots) A re-programmable,multifunctional manipulator designed to move material, parts, tools, or specialized devices through various programmed motions for the performance of a variety of tasks. Joseph Engelberger and George Devol are considered the fathers of robotics. Engelberger set up the ﬁrst manufacturing company “Unimation” to make robots, and Devol wrote the necessary patents. Their ﬁrst robot was called the “Unimate”. These robots were very successful and reliable, and saved their customer (General Motors) money by replacing staff with machines. The robot industry continues to play a major role in the automobile sector. Robots have been very effective at doing clearly deﬁned repetitive tasks, and there are many sophisticated robots in the workplace today. These robots are indus- trial manipulators and are essentially computer controlled “arms and hands”. How- ever, fully functioning androids are many years away. Table 5.2 Laws of Robotics Law Description Law Zero A robot may not injure humanity, or, through inaction, allow humanity to come to harm. Law One A robot may not injure a human being, or, through inaction, allow a human being to come to harm, unless this would violate a higher order law. Law Two A robot must obey orders given it by human beings, except where such orders would conﬂict with a higher order law. Law Three A robot must protect its own existence as long as such protection does not conﬂict with a higher order law. 22 The ﬁrst AI therapist was the ELIZA program produced by Weizenbaum in the mid-1960s. 172 5 Artiﬁcial Intelligence and Expert Systems
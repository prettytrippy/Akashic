solutions of differential equations on a computer? There are several answers. First, if the  input or stimulus to the system is a sufficiently complex function of time, it may be  impossible to evaluate integrals such as those in Theorems 1 and 3 exactly. Indeed, this is  true when a sinusoidal stimulus provides input to the Naka-Rushton function in eqn  (2.11). So approximation is necessary if we wish to determine the response of this system.  A second case is that of linear systems that represent interactions among many compo- nents. Although we can in principle write down the solution in terms of sines, cosines, and  exponentials as indicated by Theorem 4, in practice it may be more efficacious to simulate  the response for the particular initial conditions of interest.  The final, and most important, reason for employing approximation methods is to  obtain solutions to systems of nonlinear differential equations. As will be seen in sub- sequent chapters, virtually all of the truly interesting neural problems are inherently  nonlinear. Nonlinear differential equations do not generally have solutions that can be  written down in terms of known functions like exponentials. So the only way to make  detailed predictions about the temporal evolution of nonlinear neural systems is by  resorting to simulation. Therefore, let us examine some accurate approximation methods  of general utility.  5.1  Euler's method  Let us focus our attention on the problem of solving a first order differential equation of  the form:  d.v  - 7=F(.v,?)  (5.1]  where F can be a linear or nonlinear function of x and ?. At ? = 0 the initial condition is  A(0) = XQ. In most approximation methods the time variable is divided into a series of  very small steps spaced duration h apart. For any time ?,v+1 and tN this produces the  relationship:  ?w+i - tN = h  so  tN = Nh  (5.2)  Approximation and simulation  61  A finite number of time steps must be used to reduce the problem to a finite number of  calculations suitable for a computer.  The problem of approximating x may now be formulated thus: given the value of x(t^),  how do we approximate the next value, x(tN+/) = x(tN + h)l Euler's insight was to use the  Taylor series approximation to x(t) but limit the expansion to the first term in the  polynomial. Thus:  x(tN + h)  »x(tN)+h d.v  d7  (5.3)  where dx/dt is evaluated at ?#. As the value of the derivative in this expression is given  explicitly by (5.1):  x(tN + h) « x{tN) + hF(x{tN), tN)  (5.4)  Equation (5.4) is Euler's approximation to the exact solution of (5.1). Using (5.2) and  (5.4), we can start at ? = 0 and use the value x(0) = An to calculate the value of x(h). The  process is then iterated to estimate successive values of A.  As an example, let us take an equation that was solved exactly in Chapter 2:  dx =  1  d?  20v  Euler's approximation from (5.4) is:  + 40e-'/20)  with  A - ( 0 ) = 0  (5.5)  A(? + A) « x ( ? ) + - ( - * ( ? ) +40e-'/20)  As h is divided by the time constant 20 ms above, h should be chosen to be some rea- sonably small fraction of this time constant. As a first choice, let /i = 4ms or one-fifth of  the time constant. The result of simulating x(t) for 40 ms (i.e. 10 time steps) is plotted in  Fig. 5.1, where only part of the ordinate is shown to emphasize differences. Euler's  18  1 6  1 4  1 2  f  10  8  6  4  2  1  ~  1.  li  - J  i  1  1  T  r  |  .  |  /  /  ^ <  '/  Exact Solution  i J  ,  i  i  . i — i —  h = 4  h = 1  i  ,  i  i l , 1 ,  1 i 1 i 1 i  - 1 0 
determined is for the brain to combine joint angle and bone length information by vector  summation. If your goal is to reach out and grasp a wine glass in front of you, then your  brain must also include visual direction and distance in the vector computation.  The phenomenon known as path integration represents a second striking example of  vector summation in the mammalian brain. Figure 7.3 illustrates the basic phenomenon  using information extracted from photographs in a review article by Whishaw et al.  (1997). A rat emerges from its cage, which has been placed randomly below one of eight  holes in a circular platform, and begins searching for a food pellet. The search takes a  circuitous path until the food is located, at which point the rat returns directly to its cage  before eating. As rats will return directly to their cage even when blindfolded, the return  direction to the cage cannot be visually cued. Rather, the rat apparently encodes the  direction and distance of its motion along each segment of its search path and then  performs a vector computation to determine the location of its cage relative to its position  at the end of the search. Evidence from a variety of sources suggests that information  about the length and direction of each path component is stored in the hippocampus  (McNaughton et ai, 1996; Whishaw et ai, 1997).  Motor control and motion perception are other areas where vector summation is  important. In motor control, Georgopoulos and colleagues (1986, 1993) have shown that  Computation by excitatory and inhibitory networks  93  Fig. 7.3 Example of path integration by a rat searching for a food pellet. Despite a circuitous search path  from the nest, hidden below one of eight holes in a platform, the rat returns directly to the nest with the  located pellet. Path integration occurs even when the rat is blindfolded.  the direction of arm movements by monkeys is encoded by the vector sum of neural  responses in motor cortex. Furthermore, individual motor neurons each fire maximally  for a particular direction of arm movement fi, and their responses fall off as cos(fi—9),  where 6 is the direction of actual movement.  In motion perception, neurons in primary visual cortex only respond to the direction of  motion perpendicular to local lines and edges, and this information must be combined to  determine the direction of object motion. Furthermore, there are circumstances in which  local motion information cannot be integrated into a rigid motion percept, and  transparent or sliding motion is seen (Kim and Wilson, 1993). The MatLab script  Motion_Demo.m presents several motion stimuli so that these effects may be experienced.  As shown in Fig. 7.4, the program produces a set of 12 circular apertures through which  moving light and dark bars (cosine gratings) may be seen. If the program is run with  directions of ±22°, half of the apertures display bars moving at an angle of+22° and half  at an angle of —22° relative to vertically upward. In response to this stimulus in the  laboratory, subjects perceive a rigid sheet of bars moving vertically upwards, which is the  vector sum direction. Re-running the program with directions of ±68° yields a very  different percept: two sets of bars are seen sliding across one another. This transition from  rigid to transparent motion reliably occurs for all subjects when the motion directions are  approximately ±45° (Kim and Wilson, 1993).  Let us examine a modified WTA network that can both compute the vector sum of  input motion directions and simultaneously decide whether the motion is rigid or  transparent. This network represents a simplified version of a detailed neural model for  motion perception based on the physiology of a higher cortical motion area (Wilson et ai,  1992; Wilson and Kim, 1994). The model, with appropriate modifications, may be applied  to motor control, path integration, and somatosensory computations. As shown in  Fig. 7.5, 24 neurons tuned to directions of motion varying in 15° increments comprise the  44  Spikes, decisions, and actions  Rigid Motion  Hi*  v»r  v\W ,\\\> f t  Transparent Motion  Fig. 7.4  Examples of the two motion displays produced by MotionDemo.m In the left-hand pattern, the  motions are integrated into a percept of rigid upward motion, while in the right pattern motion transparency  network. Each unit in the network has a different preferred direction fi and receives an  excitatory input Fc( which is a cosine-weighted sum of A input vectors:  EQ = \ j L # c o s ( f i  (7.4)  6=1 
U2 = x2 + y2 - ay4"  (14.11)  for any a > 0 and any integer n > 1. All of this infinite class of functions are positive  definite state functions in regions of varying size surrounding the origin, and all have  negative definite derivatives near the origin. For each of these functions, however, the  estimate of the domain of attraction obtained from Theorem 13 will be different. We  proved above, using U] as a Lyapunov function, that the domain of attraction for the  unique equilibrium point of (14.3) comprises the entire phase plane. This demonstrates  that the vast majority of Lyapunov functions that might have been chosen will only prove  that a small subspace is part of the domain of attraction of the equilibrium. Nevertheless,  all Lyapunov functions are guaranteed to provide a rigorous boundary on a finite region  within the generally larger domain of attraction.  Two further points should be made here concerning Lyapunov functions before  moving on to consider their application to neural problems. First, Lyapunov also proved  several instability theorems analogous to Fheorem 13. These will not be considered here,  as they are almost never used in practice, but those interested are referred to the excellent  treatment by La Salle and Lefschetz (1961). Second, Theorem 12 states that if a Lyapunov  function exists within a region surrounding a singular point, then that point must be  asymptotically stable. Lyapunov (1892) also proved that if a singular point is asympto- tically stable, then a Lyapunov function must exist within some surrounding region. Thus,  all asymptotically stable singular points have associated Lyapunov functions, and the  existence of a Lyapunov function is both necessary and sufficient for asymptotic stability.  14.3 Divisive feedback revisited  The development of Lyapunov function theory above leaves one crucial question  unanswered: how does one construct a Lyapunov function for a given dynamical system?  There is good news and bad. First, the bad: there is no truly general algorithm for con- structing Lyapunov functions. Now the good news: several fairly simple techniques work  in most situations. One of these techniques will be illustrated here using divisive or  shunting neural feedback as an example. Divisive feedback has been implicated as part of  the retinal light adaptation circuitry (Wilson, 1997), and very similar mechanisms appear  to regulate neural responses in cortical gain control circuits (Wilson and Humanski, 1993;  Heeger, 1992; Carandini and Heeger, 1994). Based on eqn (6.3), a very simple example of  230  Spikes, decisions, and actions  such a circuit is described by the equations:  d.v  10  = —A  d /  1 + - V  (14.12)  ^ = - v + 2.v  d?  where x and y may be thought of as retinal bipolar and amacrine cell responses respec- tively and the value 10 in the first equation is the stimulus intensity (see Chapter 6). The  equilibrium states of this system are x = 2, v = 4; and x = -2.5, y = - 5 . Only the first  equilibrium state has physiological significance, and we proved in Chapter 6 that all  trajectories originating from initial conditions A > 0. y > 0 must forever remain in the  first quadrant. Thus we shall restrict consideration to the equilibrium x = 2, y = 4.  Linearization of (14.12) was used in Chapter 6 to prove that the equilibrium state in the  first quadrant is asymptotically stable, but that analysis revealed nothing about the  domain of asymptotic stability. Let us therefore see what we can learn by applying  Lyapunov function theory. To do so, let us first state a simple theorem about functions of  a particular form:  Theorem \A  continuous  that the set  is positive d  \e\<\.  : Suppose that F(x, y) and G(x,y) are continuous functions with  derivatives defined over a region of the x, y plane. Suppose further  of points where F = 0 and G = 0 is finite. Then the function:  efinite in  U(x,y)  some region  1 ,  = -F- + e FG+]-G2  surrounding each point F=0, G = 0 as long as  A proof of this theorem is easy. If; = ±1, U = (\/2)(F±  G)~, and U = 0 only when 
of values of £ to satisfy the theorem; remember that Lyapunov functions are not unique.)  4. Consider the following predator-prey equations for the ecological relationships  between wolves (W) and moose (M):  ™ =  M-\MW2  d?  16  d?  81  250  Spikes, decisions, and actions  The squared terms here might arise from the requirement that it requires two wolves to kill  a moose and eating of two moose to permit a wolf to reproduce. After solving for the  equilibria, use Theorem 15 to derive a constant of motion for this system. Using MatLab  script LotkaVolterra.m as a guide, plot several trajectories surrounding the center. (Hint:  determine a useful range of values for your constant of motion by first evaluating it at the  relevant steady state.)  5. Use the program CA31earning.m to determine the effects of storing an additional  pattern via Hebbian learning. First, determine the effect of storing another pattern that is  very different from any of the four presently in storage. Next, design a pattern that is quite  similar to one of those presently stored. For example, design a pattern that is identical to  the $ shape in the upper left of the 'Assoc' pattern but differs in its remaining elements.  How does this interfere with pattern recall? Next, determine how noise level affects  pattern recall. What is the lowest noise level in pixels at which the probability of corrupted  pattern recall is greater than 50%?  6. Consider the following two-neuron memory system:  d.v  100  = -5x + - d?  1 + e~y  dv  100  -5v + - d?  '  l+e--v+10  These equations are similar to (14.28), except that they employ the logistic function rather  than the Naka-Rushton function to describe spike rates. First, solve for the steady states,  which will require using MatFab procedure fzero as discussed in the Appendix. Now use  Theorem 16 to derive a Lyapunov function for the system (this will require integral  tables). Using CG_Lyanpunov.m as a guide, make a contour plot of this function and use it  to estimate the domain of attraction of the higher steady state using Theorem 13.  7. The autoassociative memory net for dynamical patterns depends critically on two  factors: the strength of excitation via the delayed synapses, and the strength of the  recurrent inhibition mediated by the G neuron. In the program DynamicMemory.m these  parameters are set respectively to Wdelay = 0.008 and g = 0.076 (see 14.27). For each  parameter independently determine the smallest value that will still produce a limit cycle  following stimulation by the first dynamic pattern with no added noise. For each para- meter indicate what is recalled when the parameter becomes too small, and give a  dynamical explanation of the result.  15  Diffusion and dendrites  All equations considered thus far have been ordinary differential equations, as there is  only one independent variable, namely time. However, many problems in neuroscience  involve interactions in both space and time. One major example is the spread of a post- synaptic potential along a dendrite to the cell body. A second example is the propagation  of an action potential along an unmyelinated axon. These processes are controlled by the  diffusion of ions within the dendrite and axon. Even communication between neurons  involves synaptic diffusion of neurotransmitters between cells. In this chapter, therefore,  the dynamics of diffusion processes will be explored, including the nonlinear diffusion  inherent in action potential propagation. As will be seen, solutions to the diffusion  equation can be reduced to solutions of ordinary differential equations with which we are  already familiar. In a sense, therefore, we have already learned how to solve the diffusion  equation.  In its earliest incarnation, the diffusion equation was developed by Fourier (creator of  Fourier analysis and an engineer in Napoleon's army) to describe the conduction of heat  along a wire. Diffusing ions will, of course, generate electrical currents, and these obey the  cable equation, which is mathematically identical to the diffusion equation (and to the  heat equation). As Rail (1989) has pointed out, the cable equation was so named because  it was derived by Lord Kelvin to predict electrical transmission along the first transat- lantic telegraph cable. The first applications of the diffusion or cable equation to neurons  were by Hodgkin and Rushton (1946) and by Davis and Lorente deNo (1947). The most  extensive and elegant application of cable models since that time has been the work of 
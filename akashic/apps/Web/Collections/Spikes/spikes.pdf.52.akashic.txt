equations are:  dF  '77:  cLD  ' dt'  -T +  -D +  \00(ET - kND)~+  72 + (FT -  kND)\  l00(ED-k(N~  \)D-kT)]  (7.1)  a2 +  (ED-k(N-\)D-kT)-+  90  Spikes, decisions, and actions  o  CD  1000  8 0 0  6 0 0  4 0 0  2 0 0  •  Similar  1 O  -Different  - • - - Less Similar  200 msec  per distractor  67 msec per  distractor - 0  1 2  3  4  5  Number of Distractors  Fig. 7.2  Latencies of (7.1) as a function of the number of activated distractor neurons (£>). Latency is the  time for the target (7") neuron to reach 95% of its maximum rate while suppressing D responses.  where Fis the response of whichever neuron receives information about the target and D  is the response of each of the Adistractor neurons. The constant k determines the strength  of the inhibitory feedback, while the ( )+ indicates that the parenthetical expression  evaluates to zero for negative arguments. Two points about (7.1) are worthy of note.  First, Fand D are distinguished only by the level of their inputs, with Fj > FD. Second,  we have reduced an (N + l)-dimensional system (target plus N distractors) to a two- dimensional network by making use of symmetry concepts. On the assumption that initial  conditions and inputs FD to all distractors are identical, (7.1) accurately describes the  dynamics of the entire (N + l)-dimensional system. This use of symmetry to reduce the  dimensionality of a system will be termed symmetry subsampling and will be encountered  again in Chapters 8 and 13. Note also that if some of the distractor inputs are zero, we  may simply reduce N accordingly, as these neurons will have absolutely no influence on  the resultant system dynamics.  A WTA network with five neurons, time constant r = 20 ms, and an inhibitory con- stant k = 3, is implemented in the MatLab program WTASNeurons.m. The script has  four distractors with neural inputs FD = 79.8 and one target with Ej = 80. Running the  script will reveal that the target neuron wins the competition with distractors and sup- presses the distractor activity below threshold after a latency of about 880 ms. If two of the  distractor inputs in the script are now reduced to zero so that there are only two remaining  distractors in the WTA competition, the target neuron again wins but with a much shorter  latency of 380 ms. Varying which neuron receives the stronger or target input will show  that the winning neuron is always the one responding to the target.  As shown in Fig. 7.2, this WTA neural network makes decisions by choosing the  maximum input and suppressing the others, but the dynamics cause the response latency  (time to 95% of peak response) to increase with the number of distractors. Furthermore,  the latency decreases as the distractor input FD becomes less similar to the target input EQ  (run the network with FD = 78 for example). These results, plotted in Fig. 7.2, show that a  WTA network will produce response latencies similar to those of humans (humans  Computation by excitatory and inhibitory networks  91  require some time for the motor response) in visual search tasks such as depicted in  Fig. 7.1. As the network incorporates N + 1 neurons competing in parallel, the visual  search data may be explained by a purely parallel process with inhibitory interactions,  rather than by a postulated shift from parallel to serial processing as the task becomes  more difficult. In support of this, Verghese and Nakayama (1994) have obtained data that  argue against separate parallel and serial processes in visual search.  What is the dynamical basis for variable latencies in the WTA network (7.1)? The  analysis of two inhibitory neurons in the previous chapter suggests that (7.1) will possess  a saddle point separating various asymptotically stable steady states, with only one  winning neuron active in each. When the input to the target neuron, FT is only infmite- simally greater than that to distractor neurons, we can solve approximately for the 
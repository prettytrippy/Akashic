10 -af=-G + sER'  i=i  where i = 1,  256. The time constants have been set to the reasonable value of 10 ms,  and the semi-saturation constant a = 10. The modifiable synaptic weights wtj = 0.016 if  the synapse has been modified during training and are zero otherwise. Finally, the inhi- bitory interneuron G has input synaptic weights g = 0.076.  As observed by Rolls and Treves (1998), the recurrent collaterals of CA3 cells suggest  that CA3 hippocampus is an autoassociative network. This means that stimulation by a  portion of any previously learned pattern will cause the network to recall the entire  pattern. The CA3 autoassociative network described by eqn (14.27) is implemented in the  MatLab script CA3memory.m. The network has learned to recognize four different  patterns by modification of the Hebb synapses according to (14.26), each pattern being  represented by activity in 32 CA3 neurons. If you run CA3memory.m, you can choose  which of the four patterns to recall. As a stimulus to the network, the program randomly  selects a block equal to about one-third of the pattern (10-12 active cells) and degrades  this partial image with noise consisting of 20 randomly activated cells. Four external  inputs generated in this manner are shown in the left column of Fig. 14.5. The program  then simulates (14.27) for a total of 100 ms, plotting the active neurons as white on gray  throughout the computation. As shown by the results in the right column of Fig. 14.5, the  network invariably recalls the entire learned pattern while eliminating all of the noise from  the input image. Note that the external input remains on for only the first 20 ms of the  simulation, so the final network output not only recalls and completes the pattern, it also  retains the recalled information in short-term memory as a pattern of self-sustained  neural activation!  If you run CA3memory.m several times with each pattern, you will see that a range of  different inputs varying in the nature of the added noise will all generate each correct  output. This means that the network generalizes from novel stimuli to the most similar  stimulus in its previous experience provided that the similarity is great enough (about  33% in this model)! In addition to describing the generalization inherent in memory, this  may also account for the deja vu (literally, 'already seen') experience wherein a novel  situation is experienced as being remembered. This is particularly salient in recall of the  pattern 'Assoc' illustrated at the bottom of Fig. 14.5, where a novel stimulus containing  information about one of the three elements in the memory record evokes the entire  memory of the additional associated elements.  Before turning to a mathematical analysis of (14.27), a few final comments concerning  CA3 hippocampus and the model are in order. Regarding storage capacity, calculations  240  Spikes, decisions, and actions  T H  Fig. 14.5 Patterns stored in CA3 model via Hebb synapses (right column) and examples of noisy inputs (left  column) that triggered their recall by CA3memorY.m.  developed by Hertz et al. (1991) and by Rolls and Treves (1998) indicate that the 256  neuron CA3 network can store about 12 patterns with 32 neurons active in each. You can  save and recall an additional pattern in the CA3 model by running the script CA31earning.m  (see Exercise 5). Estimates for human hippocampus, which contains about 3 x 106 neu- rons, range from about 50 000 to 70 000 on the assumption that only 1-2% of CA3  neurons are active in any given memory (Rolls and Treves, 1998). Given around figure of  1000 minutes awake per day (16.67 hours), this corresponds to storage of a memory every  12 s for 10- 14 days, the typical range of storage in the hippocampus. Thus, a scaled-up  version of our model would have a capacity appropriate to the human hippocampus but  would take impossibly long to simulate on most computers! Finally, note that each pair of  patterns in Fig. 14.5 shares several active neurons with each of the other stored patterns.  Inhibitory feedback from the G neuron in (14.27) suppresses units weakly activated by  this cross-talk. This works effectively so long as the active units common to any pair of  patterns represent a relatively small percentage of the entire patterns. Brain areas pro-
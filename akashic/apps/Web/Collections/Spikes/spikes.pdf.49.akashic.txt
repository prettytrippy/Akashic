Reference to Fig. 6.5 shows that the adaptation variable functions like a slowly varying  input driving the system, once excited, back through the bifurcation point at A.  The mathematical notion of a catastrophe or bifurcation also underlies the geology of  plate tectonics and earthquakes. As pressure builds up on tectonic plates, they compress  only slightly for a long time, so the distance between points on opposite sides of a fault line  changes little. At some point, however, the pressure becomes great enough to overcome  frictional forces, and the plates rapidly slip to a new equilibrium position, thus producing  an earthquake, which can be a true catastrophe in the vernacular sense! The mathematical  concepts analogous to those in this neural short-term memory example underlie geo- physical catastrophes as well.  6.7  Competition and neural decisions  So far we have analyzed two nonlinear neural networks: one for divisive gain control and  one for short-term memory. The former involved a negative feedback loop, while the  latter incorporated mutual excitation. A further possible interaction between two neu- rons is mutual inhibition, which will be examined here. As we shall see, the state space of  two mutually inhibitory neurons is similar to that of the memory network in having two  asymptotically stable steady states separated by an unstable saddle point. However, each  steady state in this case is defined by activity in one neuron and complete inhibition of the  Nonlinear neurodynamics and bifurcations  85  other, so this network makes one of two mutually exclusive decisions based on the relative  strengths of inputs to the two neurons.  Consider the following equations:  dF,  1  -i± =  -{-El+S{Ki-3E2))  dt  T  (6.18)  dF2  ~dTZ  S(x) -- = -(-E2  + S(K2  T  (  lOO(x)2  = \ 1202 + (x)2  u  -3F,))  x > 0  x < 0  K\ and K2 here are the stimuli to the two neurons in the network, and S(x) is again the  Naka-Rushton function from (2.11). Assume r = 20 ms. Each neuron inhibits the other  subtractively with a synaptic strength of —3. Explore the responses of this network by  running WTA2.m using various combinations of excitatory inputs K\ and K2. Above a  minimum level of excitation (about 50) and assuming initial conditions with all variables  zero, the system always switches to an equilibrium point at which the more strongly  stimulated neuron is active and the other neuron has been shut off by inhibition. This is  the simplest example of a winner-take-all (WTA) network. This name has been used to  describe such networks, because the neuron receiving the strongest stimulus will win the  inhibitory competition with the other neurons and in turn suppress all of its competitors.  Let us analyze (6.18) in the case K\ and K2 = 120. Due to the competitive inhibition, one  steady state is E\ = S(K) = 50, and F2 = S(K - 3 x 50) = S(-30) = 0. Similarly, the  reader can easily verify that E\ = 0, and F2 = 50 is also an equilibrium point. If you run  WTA2.m, you will see that the isoclines intersect at a third equilibrium point in addition to  the two above. From symmetry considerations you might expect this to occur where  E\ = F2, and this is correct. If one sets F| = F2 in either of the isocline equations in (6.18),  the MatLab roots function gives the solution E\ = E2 = 20.  As in previous examples, the stability of each steady state must next be determined. As  (50,0) and (0, 50) will be the same, let us just examine the Jacobian matrix at the former  state:  /- (6.19)  0  The eigenvalues here are obviously both identical: X = - 1/r, so (50,0) and (0, 50) are  both asymptotically stable nodes that are critically damped. At (20,20) we can use (6.10)  to evaluate the Jacobian, with the result:  T  5r  8  1  ~57  ~T /  (6.20)  86  Spikes, decisions, and actions  Setting T = 20 ms and using Linearorder2.m, the eigenvalues are: A = —0.13 and A = 
reach an equilibrium firing rate of 80. You can verify this by substitution back into (14.27)  remembering that each of the 32 active neurons receives recurrent excitation from the  remaining 31 (i.e. no self-excitation). In addition, all neurons receive an inhibitory signal  of â€”0.1G = - 19.5 in the steady state. When several patterns are stored in the network, as  in CA3memory.m different patterns will frequently have a few active neurons in common.  As long as two patterns share 15 or fewer units, however, inhibition from the G neuron  will completely suppress the response of inappropriate neurons initially excited due to  pattern overlap. You may notice this when running CA3memory.m. as parts of several  patterns are sometimes initially activated by the input but are subsequently suppressed by  inhibition. Thus, the network permits up to about a 46% overlap between distinct pat- terns stored in memory. Obviously the less overlap the better, however, and it has been  suggested that cortical circuits in several brain areas are designed to minimize overlap  among neural activity patterns before storage in regions such as CA3 hippocampus (Rolls  and Treves, 1998).  14.6 Dynamic temporal memories  The autoassociative CA3 hippocampal model just developed evolves to an asymptotically  stable steady state following brief stimulation with a noisy portion of a previously learned  pattern. While such a memory network may encode a learned face or place, we are also  Lyapunov functions and memory  247  capable of remembering complex temporal sequences, such as skilled motor control (e.g.  canoeing or piano playing) or musical themes (e.g. the ABC jingle by which many children  learn the alphabet). In these cases, it seems natural to suppose that the memory is encoded  in the form of an asymptotically stable limit cycle capable of cycling through the learned  time sequence over and over again. Kleinfeld (1986) and Sompolinsky and Kanter (1986)  simultaneously suggested the basic way in which this could be accomplished. These  authors began with an autoassociative network like the CA3 model but added a second set  of synaptic connections that conducted information from presynaptic to postsynaptic  neurons with a time delay. (Recall from Chapter 4 that time delays frequently lead to  oscillations.) Hertz et al. (1989) showed how such time delays could be made compatible  with Hebbian synaptic modification, thereby establishing the biological plausibility of the  concept. Accordingly, the development here is based on their work.  Suppose that neurons in the CA3 model are interconnected by several sets of modifiable  Hebb synapses: for one set axonal conduction and synaptic events occur extremely  rapidly (as was assumed above), while for each additional set there is a progressively  longer delay before synaptic activation. Such delays are known to be a constituent of the  neural apparatus for auditory localization (Carr, 1993), and Hertz et al. (1989) summarize  evidence for the existence of axonal conduction delays as long as 100-200 ms. At a  modifiable synapse at which the presynaptic activity has a delay of A, the simple Hebb  rule in (14.25) takes the modified form:  wy = kRi(t)Rj(t - A)  (14.40)  and an analogous modification can be made to (14.26). Note that synaptic strength tr,,  depends on contemporaneous pre- and postsynaptic activity; the time lag A results from a  delay in reaching the synapse. Whereas synapses between neurons for which A = 0 will be  symmetric: w,, = 117,, when A > 0 each pair of neurons will be coupled asymmetrically.  Thus, if a network is trained to recognize a sequence of patterns A-B-C, synapses  modified by learning among the neurons encoding A will be symmetric, while synapses  from pattern A to pattern B neurons will be asymmetric with A neurons activating B but  not the reverse. This combination of symmetric and asymmetric neural interconnections  is the key to sequence learning via Hebb synapses.  These concepts are incorporated in the MatLab script DynamicMemory.m. The net- work is the same as the CA3 network depicted in Fig. 14.4, except that the recurrent axon  collaterals activate two sets of synapses: an effectively instantaneous one and a set with a  time delay. Based on the development in Chapter 4, the delay is modeled by four expo- nential delay stages, each with a time constant r = 8 ms. The network has been trained via  Hebbian rules to recall one static pattern (a cartoon face) and one dynamic sequence of 
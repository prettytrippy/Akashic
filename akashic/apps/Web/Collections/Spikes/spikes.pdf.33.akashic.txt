Whether an oscillation can occur or not is dependent on the feedback gain as well, an issue  x_  Fig. 4.4 Negative feedback loop with a delay stage A introduced between the I and E neurons. The network  is described by (4.15).  58  Spikes, decisions, and actions  explored in the problems. If a given feedback system cannot oscillate, Routh_Hurwitz.m  cannot find a solution.  For readers with a more advanced background, here is a sketch of the proof that  introduction of an increasing number of first delay stages N as in (4.13) becomes an  exact mathematical description of a delay in the limit N-> oo.lt was shown in Chapter 2  that a cascade of (N+ 1) first order stages with identical time constants r produces the  response R{t):  R{t)=-LQN^  (4.17)  When integrated this function has unit area for all N > 1, and the peak always occurs at  7"deiay = NT\ For any desired delay, therefore, let us require that r = rde|ay/A. This is known  as the gamma function approximation to delays (MacDonald, 1989). Now, in the limit  as N^oo,  (4.17) is a function with unit area, infinitesimal width, and infinite height  centered at rdeiay. This unusual function is the Dirac 6 function (Dirac, 1958) and is a form  of 'generalized function' (Lighthill, 1958). The convolution of 6(t - rdeiav) with any  function/(?) produces exactly/(? - rdeiay). which is what we wanted to prove. Limitations  in using the gamma function with small N to approximate delays are discussed by  MacDonald (1989).  4.5 Synopsis  This chapter has been short because almost all attributes of linear second order systems  generalize to higher order systems. The major differences between second order and  higher order linear systems are practical: eigenvalues and eigenvectors are no longer as  simple to compute, although MatLabâ„¢ is an enormous aid here. Some scientists  apparently believe that ready access to computers has obviated the need to understand  and utilize analytical approaches to dynamical systems. This perception is misguided for  two reasons. First, a scientist cannot hope to create and analyze a neural model derived  from her/his research without a sophisticated appreciation of the underlying mathe- matics. Second, without analytical techniques, attempts to find parameter values that  generate particular types of solutions, such as the oscillations in our simulation of  respiration, can degenerate into laborious trial-and-error computer simultions. Begin- ning in the next chapter, we shall integrate computer simulations with nonlinear analysis,  emphasizing the complementary insights to be gained from each.  4.6  Exercises  1. Consider the following equation:  dX  ^d7  -3  b  4  Higher dimensional systems  59  (a) Determine the value of b that will cause the system to oscillate, (b) Write down the  general form of the analytical solution in terms of exponentials, etc. (Just write down the  combination of functions with their eigenvalues that will be involved; you need not solve  for the eigenvectors.)  2. Extend the example of delays in the feedback system in eqn (4.15) by introducing a  second delay between the excitatory neuron and the inhibitory neuron in addition to the  delay already present. This will produce a fourth order system. Assume that the constant 6  is the same for both delay stages, and solve for 6 to produce an oscillation. How does the  total feedback delay, 26, compare with the delay calculated for just one stage in the  chapter?  3. Consider the following example of a feedback system in which there is a delay in neural  transmission from the excitatory neuron E to the inhibitory neuron I. The strength of the  feedback inhibition depends on a parameter g. Determine how the delay depends on g by  solving for 6 to produce oscillations for the following values: g= 10,15,25. Also deter- mine the frequency of the oscillation in Hz (not radians) in each case assuming the time  constants are in ms. What trends do you observe as the inhibitory feedback becomes  stronger?  5-5<-'+A>  Approximation and simulation  Systems of linear differential equations with constant coefficients can be solved exactly in  terms of sine, cosine, and exponential functions, with the occasional polynomial thrown  in when several eigenvalues are identical. Why, then, is it necessary to approximate the 
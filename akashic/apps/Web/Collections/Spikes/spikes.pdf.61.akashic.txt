(Wilson and Cowan, 1973). This network incorporates two cell types distributed in space  and interconnected in all possible ways. Consistent with anatomy, the recurrent excita- tion remains relatively localized spatially, while inhibitory connections extend over a  broader range. Similarly balanced interactions between F and / neurons have been  proposed recently to explain a diverse range of cortical phenomena (Douglas and Martin,  1991; Adinie/a/., 1997; DeBellis et al., 1998; Somers et al, 1998).  The original Wilson-Cowan (1973) equations were written in the form:  dF(A')  dllx)  T-^=-I(x)+  1  d?  E(x) + (1 - kE(x))SE J2 M'EE£W - J2 "'IE/(-V) +  P{x)  kI(x))Sl I YJ wElE(x) - J J U,|/(A) ± (2(A) j  (7.19)  where F(.v) and /(.v) are the mean firing rates of neurons at position x, and P, Q are the  external inputs to the network. The four connectivity functions u„ represent the spatial  spread of synaptic interconnections in the network. Based on the work of Sholl (1956)  these functions were chosen to be decaying exponential functions of distance:  Wjj(x - .v') = by exp(-|.v - x'\/ojj)  (7.20)  Cortical Position  Fig. 7.10 Network of excitatory (arrows) and inhibitory (solid circles) interactions among /fand /neurons  in cerebral cortex. Excitatory interactions among the E cells have a short spatial extent, while inhibitory  feedback from / cells is longer range. For clarity, only one / neuron is shown.  Computation by excitatory and inhibitory networks  105  where by gives the maximum synaptic strength, CT,; is the space constant controlling the  spread of connectivity, and /',/'= F, /. One might just as easily have chosen a Gaussian  function to describe the synaptic connectivity, but any monotonically decaying distance  function will give rise to the same types of dynamical behavior. The sigmoidal nonlinear  functions S were originally chosen to be hyperbolic tangents, but here we shall use the  Naka-Rushton function from (2.11) with /V= 2 instead:  Finally, (7.19) can be transformed by setting A: = 0 to obtain equations in which 5  describes the neural spike rate. The resulting network equations are:  T^7T = ~ £ ( v ) + 5E (^"'EE£( Y) - Y, "'IE/(V) + P{x)  T 7i7 = ~I(x) + 5l ( E M'EI£M - E '"'"'M + 2W  (7.22)  where it',/ and 5, are defined in (7.20) and (7.21) respectively. These equations exhibit the  same dynamics as (7.19).  In a complex neural network like (7.22) one is immediately confronted with the issue of  choosing reasonable values for the various parameters, and this must generally be done in  the absence of experimental evidence adequate to specify them all precisely. However, it is  generally possible to use appropriate physiological constraints to place bounds on rea- sonable parameter values. Three such constraints are particularly important in studying  spatially extended neural networks. First, the resting state F = 0, 7 = 0 should be  asymptotically stable so that the network will not respond to small random inputs. Given  the form of S,, this condition is automatically satisfied, since (7.22) linearizes to  T dE/dt = —E, T dl/dt = —I'm the neighborhood of the resting state. Second, the spatial  spread of recurrent inhibition is generally greater than that of recurrent excitation. This  condition will be satisfied if:  0"EI = <7"IE > 0"EE  (7.23)  The final condition is that there should be no spatially uniform steady states other than  the resting state in the absence of external stimulation. States of uniform excitation  throughout a network have little interest, as they do not occur physiologically (except  possibly during seizures). In a uniform state E(x,t) = E(t) and I(x,t) = /(?). Let us  therefore approximate the spatial sums in (7.22) weighted by the connectivity functions ir„  as integrals over an effectively infinite distance (i.e. a distance large with respect to the 
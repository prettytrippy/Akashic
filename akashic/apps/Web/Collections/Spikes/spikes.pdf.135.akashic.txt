As both partial derivatives are continuous for all x and y, U is a state function of the  system. However, the function U = \/(.x + y) is not a state function, as the partial  derivatives are discontinuous wherever (x + y) = 0.  State functions are valuable in analyzing differential equations because they create a  landscape of hills and valleys in the state space. We will mainly be concerned with valleys  and whether trajectories flow downward to steady states located at the bottom. First,  therefore, let us define a mathematical valley with a steady state at the bottom. The key  concept is that of a positive definite state function in a region R of state space:  Definition:  definite in  (a) F'(.\'o) =  (b) U(x) >  A state  a region  = 0 and  0 m R if  function U(x)  R surrounding  X 7^ A',).  in  an  an A-dimensional state  internal singularity An  space  f:  x is positive  Consider a simple dynamical system with a unique singular point at the origin:  d.v  2  — = —x — y — ixy  dv  — = - r + A  d?  This might be considered to be a nonlinear version of the retinal negative feedback circuit  in Chapter 3, as (14.3) differs only by the addition of the nonlinear term in the dx/dl  equation. Both of the following functions satisfy the definition of positive definite state  functions around the origin:  Ui = x2 + r  (14.4)  U2 = x- + t- - y4  For U\ Ihe region R includes the entire plane, while the region within which U2 is a  positive definite state function is limited by \y\ < 1. Evidently, positive definite state  Lyapunov functions and memory  225  functions are not unique, so many different ones can be defined in different regions  enclosing each singular point of a dynamical system.  Given a positive definite state function U defining a mathematical valley around a  singularity, let us determine whether trajectories of the system flow downhill to the  singularity at the bottom. This requires calculation of the temporal change of a positive  definite state function along trajectories of the system. As U(x,y) does not explicitly  include time, it can vary with time only as a result of the time variation of x and y as the  system evolves. This can be calculated using the partial derivatives of U.  dU  OUdx dUdv  , „ r ,  — =  1  4.5  d?  dx dt  dv dt  y  '  As d.v/d? and dy/dt are always determined by the dynamical equations of the system as  explicit functions of A and y, (14.5) can be evaluated exactly at any point in the phase  plane. Taking the dynamics from (14.3) and U\ from (14.4) as an example, evaluation of  (14.5) produces the result:  dlh  „ dx  „ dp  -r-L = 2 v7r- + 2i'7F- d?  d?  " d?  ( H 6 )  = -2A-: - 6x2y2 - 2 r  Thus, at any point in the state space dU\/dt can easily be calculated. Equation (14.5)  readily generalizes to an A-dimensional system with variables x, as follows:  —  = F,(x]  •••xN)  6U  A<"  E uu  _,dx~,  (14.7)  F,  14.2 Lyapunov functions and asymptotic stability  These ideas may now be related to the asymptotic stability of an equilibrium point in the  following intuitive way. A positive definite state function in a region surrounding an  equilibrium point at A0 defines a mathematical valley with x0 as its lowest point. If all  trajectories of the system flow like water down to the bottom of the valley, all will end up at  x0. This, however, satisfies the definition of asymptotic stability: all trajectories within a  neighborhood of a singular point approach it as ? -> oo. These ideas are made precise in  226  Spikes, decisions, and actions  the Lyapunov Function Theorem:  Theorem 12 (Lyapunov Functions): Consider an A-dimensional dynamical system  defined by the equation:  £-*>  Let U(x) be a positive definite state function of the system in a region R  surrounding an equilibrium point at .Y0. If either of the following conditions is 
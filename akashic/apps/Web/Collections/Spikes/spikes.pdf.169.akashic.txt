principles may now be recognized as the basis of nonlinear dynamical analysis. The  primary strategy throughout the book has been to first solve for the steady states and then  linearize about each based on Taylor series expansion. The local stability of each steady  state is then determined by the eigenvalues of the Jacobian. which are solutions of the  characteristic equation. If the eigenvalues are imaginary, oscillatory sine and cosine  solutions result. It is the properties of the exponential function which reduce differential  equations to solutions of polynomials. These concepts, exponential functions with real or  imaginary exponents and Taylor series, constitute the bedrock upon which much of  nonlinear dynamics is founded.  In addition, a number of geometrical principles have emerged that extend linearized  analysis in important ways. The first of these we encountered was the Poincare-Bendixon  theorem. Although limited to two dimensions, this elegant theorem can prove the exist- ence of limit cycles throughout the phase plane using inherently geometric and global  considerations. The Hopf bifurcation theorem is also predicated on geometric con- siderations: a multi-dimensional system must decay onto a two-dimensional subspace  within which limit cycle analysis becomes possible.  Without doubt, the most intellectually sophisticated application of geometry to non- linear dynamics results from the theorems of Lyapunov. This brilliant mathematician  realized that nonlinear dynamics could be understood by defining a landscape of hills and  valleys where solutions to nonlinear differential equations descended to the lowest points.  This is clearly the most global approach to analyzing nonlinear systems. Although the  Lyapunov function approach has inherent difficulties associated with the creation of  appropriate functions, I shall argue below that the geometrical interpretation of dynamics  revealed by Lyapunov even provides insight into the inception of mathematics in the brain.  Turning to those aspects of nonlinear dynamics of greatest relevance for neuroscience,  several further principles have emerged. First, many neural problems have at least two  widely different time scales associated with the dynamics. This has permitted us to analyze  the fast variation with the slow assumed constant, thereby reducing the dimensionality  and complexity of the problem. Neuronal bursting is a classical example of this, because  the bursting is typically generated as the slower variable (e.g. Ca2+ current) sweeps the  faster variables (e.g. Na+ spiking) back and forth through a bifurcation.  Another very important observation is that neurodynamics almost always incorporates  either sigmoid (e.g. Naka-Rushton or logistic functions) or cubic nonlinearities. (As the  cube root is also sigmoidal, albeit without finite asymptotes, cubics are sigmoidal along  the orthogonal axis.) Restriction to such a very small subset of all possible nonlinearities  has enabled us to develop a comprehensive treatment of the dynamical foundations of  neuroscience. Sigmoid functions and cubics share the important property that they can be  intersected by a straight line in either one or three points, and this property underlies the  existence of multiple steady states and hysteresis.  Nonlinear dynamics and brain function  281  An interplay between positive and negative feedback constitutes the final key theme in  neural dynamics. At the level of networks this takes the form of a balance between  recurrent excitation and inhibition, as exemplified by the Wilson-Cowan (1972, 1973)  equations. At the level of single neurons, positive feedback is exemplified by the voltage- dependent opening of ion channels (e.g. Na+ or Ca2+) that cause further depolarization  of the cell, while negative feedback is manifested by voltage-dependent channels pro- ducing hyperpolarization. In both cases the underlying dynamical characteristics are  remarkably similar. Both networks and isolated neurons can produce limit cycles, and  both can also produce hysteresis switching as witnessed by short-term memory circuits in  networks and plateau potentials in neurons. Thus one might epitomize the dynamics of  neuroscience as the nonlinear sigmoid dynamics of interacting positive and negative  feedback pathways.  16.2 Strategies for neural modeling  As in any active and creative area of science, there are a vast range of strategies for  attacking neural modeling problems. However, certain considerations and compromises  are faced again and again. The first and most important consideration is the level of  description of the neural elements. The alternative possibilities can be rank ordered in  terms of increasing complexity. The simplest description of a neuron is certainly in terms  of its spike rate as described by a Naka-Rushton or other sigmoid function. A more  complex description is the isopotential neuron with multiple ionic currents that combine  to produce individual spike outputs. However, as demonstrated elegantly by Booth and  Rinzel (1995), firing patterns such as those involving plateau potentials require a two- compartment model for their description. Two, of course, is the lower limit of com-
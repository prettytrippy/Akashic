dt = ~y  .18)  withy= 1 at time? = 0. (The reader may verify this by substituting y = 1/(1 +?)intothe  second equation.) Equations in which the independent variable ? does not appear expli- citly in any of the parameters are said to be autonomous systems. (We will, of course, deal  with the case where the stimulus to a neuron or network is time-varying.)  The plan of the book is straightforward. In order to understand nonlinear dynamics,  one must first grasp certain fundamental aspects of linear dynamics. These are contained  in Chapter 2, which discusses first order linear systems, and Chapters 3 and 4, which  extend the analysis to second and higher order linear systems. Before delving into non- linear differential equations, Chapter 5 develops techniques for simulating dynamical  systems on the computer, the focus being on Runge-Kutta methods. Chapters 6 and 7  introduce the analysis of nonlinear neural systems with multiple equilibrium points, and  Chapter 8 focuses on limit cycle oscillations in simple neural systems. With this back- ground. Chapter 9 analyzes equations for action potential generation related to the  Hodgkin-Huxley equations, and Chapter 10 extends this to bursting neurons controlled  by limit cycles within limit cycles. Chapter 11 provides a brief introduction to neural  chaos. Neural synchrony and motor control (with the lamprey swimming oscillator  as a prime example) are covered in Chapters 12 and 13. Chapter 14 provides a brief  introduction to Lyapunov function theory with applications to long-term memory.  Chapter 15 provides an introduction to the one partial differential equation of greatest  relevance to neuroscience: the diffusion or cable equation. This represents a straight- forward extension of the foregoing material, as the method of separation of variables  reduces the diffusion equation to ordinary differential equations. Applications to den- dritic and action potential propagation, as well as compartmental neurons, are explored.  Finally, Chapter 16 concludes with a resume of general principles underlying nonlinear  neural dynamics.  MatLab scripts are included with this book to enable the reader to simulate all of  the examples in the text without spending excessive time programming. In addition,  many exercises at the end of chapters can be approached by making small modifications  in the MatLab programs provided. MatLab was chosen because it is widely used by  12  Spikes, decisions, and actions  neuroscientists and because the same script will run on the Macintosh, Windows, and  under UNIX. Although the MatLab simulations are not essential for readers with  sophisticated mathematical backgrounds, they should be quite valuable to the neu- roscience student exploring nonlinear dynamics for the first time.  I have always found nonlinear dynamics to be conceptually rich and fascinating, and I  have truly enjoyed writing Spikes, decisions, and actions. I sincerely hope the reader will  find the book exciting as well as informative.  First order linear differential  equations  A differential equation describes the change in neural responses (or ionic concentrations,  etc.) between the present time ? and a time (? + d?), which lies infinitesimally in the future,  and it describes this change as some function of all the physiologically relevant variables  at time ?. The order of a differential equation is defined as the highest derivative present in  the equation. As will be seen in the next chapter, this is equivalent to the number of  coupled first order equations in a system of differential equations. In this chapter I  introduce the simplest differential equation of major importance in science: the first order  linear differential equation with constant coefficients. Solutions of this equation form the  basis for understanding higher order equations, both linear and non-linear. Despite its  linearity, however, the first order equation is still capable of describing the spike rate of a  single neuron in response to stimulation, and we shall see that it can also describe  interactions between postsynaptic potentials.  2.1 The fundamental first order equation  Let us begin our treatment of differential equations by considering the simplest, yet most  fundamental of all differential equations in the sciences:  d.v  1  - T - = - - - V  2.1  d?  r  This equation states that the rate of change of the function x(t) as a function of time ? is  equal to a constant times the function itself. The time constant, r, can be shifted to the left  side of the equation by simple multiplication, but the form (2.1) will be useful for our  present purposes. The temporal units of r are the same as ? (i.e. milliseconds, ms, or  fraction of a second). We can solve (2.1) by substituting an exponential function and then  making use of its derivative from (1.2):  x(t) = Aec",  so 